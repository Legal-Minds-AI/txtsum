{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yc0A34Q2J4Vr"
      },
      "outputs": [],
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'indian-penal-code-ipc-sections-information:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F4280663%2F7368197%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240402%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240402T141226Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Db71aa4609fe7404d350a3ef552df655515d924d5eb9191f6440b0fd2738139c6fca383574c9c0c39626c33b58116ab7a282b12d13388243c6f02cf37dbbabace24bf73d726ef8ddc66466015b50776a26170546be734bd739ed80072f450def3279d1c1eb620fd75793a482b2be22dd5d7b74ff9b57ec008a7d9d35ad421938a4564fd4eef40a13d1fcf872c952b59eeeeff5c7ac282826e85f15177a10dacd332ee99204c07edd05dca4e913438c5c6418e123efc5901a0debdb2c126dd736c27bf8284441cbc222caa2d605088c2a2c88e21a38c3bc42f2a9f8d510c6f113ba80d2255d57b0de46b40f6f95f231089dc133dd8db388dfb80e63b76bfa69248'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3dd54cc1-a1bf-4585-942d-169dd7eea407",
        "_uuid": "5df5145d-2dd7-43f3-88d9-ff03e4bbb3a4",
        "execution": {
          "iopub.execute_input": "2024-01-22T04:16:22.379918Z",
          "iopub.status.busy": "2024-01-22T04:16:22.379435Z",
          "iopub.status.idle": "2024-01-22T04:16:22.838977Z",
          "shell.execute_reply": "2024-01-22T04:16:22.836793Z",
          "shell.execute_reply.started": "2024-01-22T04:16:22.379865Z"
        },
        "id": "zAPUTVrXJ4Vt",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f3ba0498-a447-40f5-b7b2-b3d690f2aa89",
        "_uuid": "9dca7c47-bc13-4f3b-9a0c-66ba6ac54bbd",
        "execution": {
          "iopub.execute_input": "2024-01-22T04:18:01.907934Z",
          "iopub.status.busy": "2024-01-22T04:18:01.907527Z",
          "iopub.status.idle": "2024-01-22T04:18:01.96486Z",
          "shell.execute_reply": "2024-01-22T04:18:01.963674Z",
          "shell.execute_reply.started": "2024-01-22T04:18:01.907902Z"
        },
        "id": "DtZT0xITJ4Vu",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "file_path = '/kaggle/input/indian-penal-code-ipc-sections-information/ipc_sections.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Display the first few rows of the dataset to get an overview\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a88a55d2-e4dd-480e-b814-1a1f8505e1be",
        "_uuid": "5bcc43ae-8811-40ac-a2fd-186a6917671a",
        "execution": {
          "iopub.execute_input": "2024-01-22T04:19:43.347177Z",
          "iopub.status.busy": "2024-01-22T04:19:43.34675Z",
          "iopub.status.idle": "2024-01-22T04:19:43.384189Z",
          "shell.execute_reply": "2024-01-22T04:19:43.383029Z",
          "shell.execute_reply.started": "2024-01-22T04:19:43.347145Z"
        },
        "id": "3sXhP6uAJ4Vu",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/kaggle/input/indian-penal-code-ipc-sections-information/ipc_sections.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Extract relevant columns for input features and target variable\n",
        "X = df[['Offense', 'Punishment']].values  # Input features\n",
        "y = df['Description'].values  # Target variable\n",
        "\n",
        "# Print the first few rows of X and y to verify the data\n",
        "print(\"Input Features (X):\")\n",
        "print(X[:5])\n",
        "\n",
        "print(\"\\nTarget Variable (y):\")\n",
        "print(y[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1ebf2f48-28a2-470c-a867-c9f18ea2b7b5",
        "_uuid": "8751788d-fd2c-407c-acfa-e5f79683423a",
        "id": "VRXvHTNNJ4Vu",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "# Check the data types of 'Offense' and 'Punishment'\n",
        "print(\"Data Types:\")\n",
        "print(\"Offense:\", X[:, 0].dtype)\n",
        "print(\"Punishment:\", X[:, 1].dtype)\n",
        "\n",
        "# Convert 'Offense' and 'Punishment' to strings if they are not already\n",
        "X[:, 0] = X[:, 0].astype(str)\n",
        "X[:, 1] = X[:, 1].astype(str)\n",
        "\n",
        "# Combine 'Offense' and 'Punishment' into a single text feature\n",
        "X_text = X[:, 0] + ' ' + X[:, 1]\n",
        "\n",
        "# Continue with the rest of the code...\n",
        "\n",
        "\n",
        "# Combine 'Offense' and 'Punishment' into a single text feature\n",
        "X_text = X[:, 0] + ' ' + X[:, 1]\n",
        "\n",
        "# Use CountVectorizer to convert text data to numerical format\n",
        "vectorizer = CountVectorizer()\n",
        "X_numerical = vectorizer.fit_transform(X_text)\n",
        "\n",
        "# Use LabelEncoder to convert the target variable to numerical format\n",
        "label_encoder = LabelEncoder()\n",
        "y_numerical = label_encoder.fit_transform(y)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_numerical, y_numerical, test_size=0.2, random_state=42)\n",
        "\n",
        "# Print the shape of the numerical features and target variable\n",
        "print(\"Shape of X_numerical:\", X_numerical.shape)\n",
        "print(\"Shape of y_numerical:\", y_numerical.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ee55278b-218e-4af5-bda5-67821e10a47e",
        "_uuid": "b8e1aee6-c444-4dc1-b853-e27b32313ed2",
        "execution": {
          "iopub.execute_input": "2024-01-22T04:23:20.530124Z",
          "iopub.status.busy": "2024-01-22T04:23:20.529569Z",
          "iopub.status.idle": "2024-01-22T04:23:35.889695Z",
          "shell.execute_reply": "2024-01-22T04:23:35.888416Z",
          "shell.execute_reply.started": "2024-01-22T04:23:20.530077Z"
        },
        "id": "UAqfUFsCJ4Vv",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Define the neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(len(np.unique(y_numerical)), activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4b66570f-1940-4c1d-a10c-b0a16867680e",
        "_uuid": "742e762c-7102-42f4-a10e-420d540195af",
        "execution": {
          "iopub.execute_input": "2024-01-22T04:57:36.8389Z",
          "iopub.status.busy": "2024-01-22T04:57:36.837426Z",
          "iopub.status.idle": "2024-01-22T04:59:00.106334Z",
          "shell.execute_reply": "2024-01-22T04:59:00.105147Z",
          "shell.execute_reply.started": "2024-01-22T04:57:36.83882Z"
        },
        "id": "Gg_E8GQrJ4Vv",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "from sklearn.preprocessing import LabelEncoder  # Add this import\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/kaggle/input/indian-penal-code-ipc-sections-information/ipc_sections.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Extract relevant columns for input features and target variable\n",
        "X = df[['Offense', 'Punishment']].astype(str).values  # Convert to string\n",
        "y = df['Description'].values  # Target variable\n",
        "\n",
        "# Convert labels to numerical format using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "\n",
        "# Number of unique classes in your dataset\n",
        "output_neurons = len(np.unique(y))\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Combine 'Offense' and 'Punishment' into a single text feature\n",
        "X_text_train = X_train[:, 0] + ' ' + X_train[:, 1]\n",
        "X_text_test = X_test[:, 0] + ' ' + X_test[:, 1]\n",
        "\n",
        "# Use CountVectorizer to convert text data to numerical format\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_numerical = vectorizer.fit_transform(X_text_train)\n",
        "X_test_numerical = vectorizer.transform(X_text_test)\n",
        "\n",
        "# Compute sample weights for balancing classes\n",
        "sample_weights = compute_sample_weight('balanced', y_train)\n",
        "\n",
        "# Define the neural network model with adjustments\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train_numerical.shape[1], activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Set the number of output neurons to match the unique classes\n",
        "model.add(Dense(output_neurons, activation='softmax'))\n",
        "\n",
        "# Compile the model with sample weights\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with sample weights\n",
        "history_weighted = model.fit(X_train_numerical.toarray(), y_train, epochs=1000, batch_size=100, validation_split=0.2, sample_weight=sample_weights)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(X_test_numerical.toarray(), y_test)\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "809a7aa8-ccfd-425c-898c-9b904fccbacb",
        "_uuid": "916e636c-772c-4269-9a47-c7b00ff605b8",
        "execution": {
          "iopub.execute_input": "2024-01-22T05:19:03.246225Z",
          "iopub.status.busy": "2024-01-22T05:19:03.245731Z",
          "iopub.status.idle": "2024-01-22T05:19:03.352687Z",
          "shell.execute_reply": "2024-01-22T05:19:03.351561Z",
          "shell.execute_reply.started": "2024-01-22T05:19:03.24619Z"
        },
        "id": "pvqmM_3pJ4Vv",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Your specific input\n",
        "input_text = \"robbery\"\n",
        "\n",
        "# Combine with additional information if needed\n",
        "# For example, if you have additional context in another variable 'context_text'\n",
        "# you can concatenate them: input_text = input_text + ' ' + context_text\n",
        "\n",
        "# Use CountVectorizer to convert the input text to numerical format\n",
        "input_numerical = vectorizer.transform([input_text])\n",
        "\n",
        "# Make a prediction using the trained model\n",
        "prediction = model.predict(input_numerical.toarray())\n",
        "\n",
        "# If you want the predicted class label (assuming one-hot encoding is used)\n",
        "predicted_label = np.argmax(prediction)\n",
        "\n",
        "# If you want to convert the predicted label back to the original label\n",
        "predicted_label_original = label_encoder.inverse_transform([predicted_label])\n",
        "\n",
        "# Display or use the prediction as needed\n",
        "print(predicted_label_original)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b293e057-afae-487c-8d92-7a1732062036",
        "_kg_hide-output": true,
        "_uuid": "2816d055-73b1-4758-9486-143bf6fe47fb",
        "execution": {
          "iopub.execute_input": "2024-01-22T05:42:45.744306Z",
          "iopub.status.busy": "2024-01-22T05:42:45.742714Z",
          "iopub.status.idle": "2024-01-22T05:42:45.790515Z",
          "shell.execute_reply": "2024-01-22T05:42:45.789246Z",
          "shell.execute_reply.started": "2024-01-22T05:42:45.744258Z"
        },
        "id": "TiCinYCFJ4Vv",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model.save('/kaggle/working/text_prediction_model.keras')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "notebook286c145dfe",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 4280663,
          "sourceId": 7368197,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30635,
      "isGpuEnabled": false,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
